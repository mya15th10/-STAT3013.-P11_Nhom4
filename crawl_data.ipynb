{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":27629,"status":"ok","timestamp":1731937964682,"user":{"displayName":"Đạt Nguyễn Vĩnh","userId":"04880703526488901818"},"user_tz":-420},"id":"-ki4mEpLqu8k","outputId":"5a0a0cd7-6995-4e52-c154-171927f9babf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"Cq9TK1uCaCxe","executionInfo":{"status":"ok","timestamp":1731937968338,"user_tz":-420,"elapsed":384,"user":{"displayName":"Đạt Nguyễn Vĩnh","userId":"04880703526488901818"}}},"outputs":[],"source":["import sys\n","sys.path.insert(0, '/content/drive/MyDrive/stat_project/analysis')"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"executionInfo":{"elapsed":485,"status":"ok","timestamp":1731937972105,"user":{"displayName":"Đạt Nguyễn Vĩnh","userId":"04880703526488901818"},"user_tz":-420},"id":"nj9sDThAbp8V","outputId":"95143605-171a-4f24-8938-2d2c88f10e07"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/stat_project/analysis\n"]}],"source":["%cd /content/drive/MyDrive/stat_project/analysis"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jVo-CtdS5U-C","executionInfo":{"status":"ok","timestamp":1731937986643,"user_tz":-420,"elapsed":11723,"user":{"displayName":"Đạt Nguyễn Vĩnh","userId":"04880703526488901818"}},"outputId":"c2cf5dd5-8db6-4fd6-8d8d-91dbff23937c"},"outputs":[{"output_type":"stream","name":"stdout","text":["No more or invalid data.\n","Data has been saved to /content/drive/MyDrive/stat_project/analysis/trainingset/FPT_stock_data.csv\n"]}],"source":["import http.client\n","import json\n","import pandas as pd\n","import os\n","from datetime import datetime\n","\n","# Create a folder to save data if it doesn't exist\n","output_folder = '/content/drive/MyDrive/stat_project/analysis/trainingset'\n","if not os.path.exists(output_folder):\n","    os.makedirs(output_folder)\n","\n","# Function to crawl data from FPT's API with multiple pages and customizable date range\n","def fetch_fpt_data(symbol, start_date, end_date):\n","    headers = {\n","        \"Accept\": \"application/json\",\n","        \"Referer\": \"https://s.cafef.vn/\",\n","        \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n","    }\n","\n","    conn = http.client.HTTPSConnection(\"s.cafef.vn\")\n","    all_data = []\n","    page_index = 1\n","    page_size = 100  # Customize the number of records per page if needed\n","\n","    while True:\n","        url = f\"/Ajax/PageNew/DataHistory/PriceHistory.ashx?Symbol={symbol}&StartDate={start_date}&EndDate={end_date}&PageIndex={page_index}&PageSize={page_size}\"\n","        conn.request(\"GET\", url, headers=headers)\n","        res = conn.getresponse()\n","        data = res.read()\n","        conn.close()\n","\n","        if res.status != 200:\n","            print(f\"status code: {res.status}\")\n","            return None\n","\n","        try:\n","            json_data = json.loads(data.decode(\"utf-8\"))\n","\n","            # Check if the 'Data' field exists and contains data\n","            if \"Data\" in json_data and \"Data\" in json_data[\"Data\"] and json_data[\"Data\"][\"Data\"]:\n","                page_data = pd.json_normalize(json_data[\"Data\"][\"Data\"])\n","                all_data.append(page_data)\n","                page_index += 1  # Move to the next page\n","            else:\n","                print(\"No more or invalid data.\")\n","                break  # Exit the loop when no more data is available\n","        except json.JSONDecodeError as e:\n","            print(f\"Error decoding JSON: {e}\")\n","            return None\n","\n","    # Combine all data from pages into a single DataFrame\n","    if all_data:\n","        full_data = pd.concat(all_data, ignore_index=True)\n","        full_data = full_data[[\"Ngay\", \"GiaDongCua\", \"GiaMoCua\"]]  # Select columns for Date, Close Price, and Open Price\n","        full_data.rename(columns={\"Ngay\": \"date\", \"GiaDongCua\": \"close_price\", \"GiaMoCua\": \"open_price\"}, inplace=True)\n","\n","        # Save the data to a CSV file\n","        output_path = os.path.join(output_folder, f'{symbol}_stock_data.csv')\n","        full_data.to_csv(output_path, index=False, encoding='utf-8-sig')\n","        print(f\"Data has been saved to {output_path}\")\n","    else:\n","        print(\"No data to save.\")\n","\n","# Run the function to crawl data with the desired parameters\n","symbol = \"FPT\"\n","start_date = \"2020-01-01\"  # Start date (format: YYYY-MM-DD)\n","end_date = datetime.now().strftime(\"%Y-%m-%d\")  # Current date\n","fetch_fpt_data(symbol, start_date, end_date)\n"]}]}